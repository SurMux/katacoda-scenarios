Glückwunsch! Das Katacoda Szenario ist nun erfolgreich abgeschlossen.
Das Szenario entstand anlässlich der Prüfungsleistung der Data Warehouse Vorlesung an der DHBW Stuttgart.
Das Bearbeiten dieses Szenarios sollte theoretische als auch praktische Grundlagen zum Thema Datenströme in Apache Kafka übermittelt haben.

## Übermittelte Inhalte

- Theoretische Grundlagen von Apache Kafka
- Einrichtung von Apache Kafka und Zookeeper mit Hilfe von Docker
- Implementierung von Producern und Consumern
- Einlesen und Ausgeben von Daten in Apache Kafka

## Quellen

[1] A. Buckenhofer, „Vorlesung Data Warehouse - 02 Tools“, Daimler TSS, 4. November 2021. Online abrufbar unter: https://elearning.dhbw-stuttgart.de/moodle/pluginfile.php/408259/mod_resource/content/1/Buckenhofer-DWH02-Tools.pdf. Letzter Zugriff am 25. November 2021.

[2] O’Reilly Media, Inc., „Chapter 1. Meet Kafka“, 2021. Online abrufbar unter: https://www.oreilly.com/library/view/kafka-the-definitive/9781491936153/ch01.html. Letzter Zugriff am 24. November 2021.

[3] Gavin McDonald, „Apache ZooKeeper“, 15. Januar 2021. Online abrufbar unter: https://cwiki.apache.org/confluence/display/ZOOKEEPER/Index. Letzter Zugriff am 25. November 2021.

[4] O’Reilly Media, Inc., „Chapter 4. Kafka Consumers: Reading Data from Kafka“, 2021. Online abrufbar unter: https://www.oreilly.com/library/view/kafka-the-definitive/9781491936153/ch04.html. Letzter Zugriff am 25. November 2021.

[5] Dario Radečić, „Apache Kafka in Python: How to Stream Data With Producers and Consumers“, 27. September 2021. Online abrufbar unter: https://towardsdatascience.com/apache-kafka-in-python-how-to-stream-data-with-producers-and-consumers-307e84ca8bdb. Letzter Zugriff am 18. November 2021.